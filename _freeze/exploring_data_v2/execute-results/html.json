{
  "hash": "a822c7c5080725ed7cd1d6d068b59481",
  "result": {
    "engine": "knitr",
    "markdown": "## Getting Started with the Data Exploration Pipeline\n\n### Set-up\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#install.packages(\"pacman\")\n\n\npacman::p_load(tidyverse, here)\n\n#tidyverse required for tidy workflows\n#rio required for importing and exporting data\n#here required for managing file paths\n```\n:::\n\n\n\n\n:::{style=\"text-align:justify\"}\n\n*Note*\n\n*The shortcut for code commenting is `Ctrl+Shift+C`.*\n\n### Load Data\n\n\n> The dataset we will be working with has been cleaned (to an extent) for the purposes of this workshop. It is a dataset about NHANES that has been took from the `NHANES` and cleaned up and modified for our use. \n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Check the file path\nhere::here(\"data\", \"nhanes_basic_info.csv\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"D:/websites/r4hta_india/data/nhanes_basic_info.csv\"\n```\n\n\n:::\n\n```{.r .cell-code}\n# Read Data\ndf <- read_csv(here(\"data\", \"nhanes_basic_info.csv\"))\n```\n:::\n\n\n\n\nTry the following functions using tb as the argument:\n\n-   `glimpse()`\n-   `head()`\n-   `names()`\n\n\n\n\n\n\n\n\n\nNow, we will be introducing you to two new packages:\n\n1.  `dplyr`\n2.  `skimr`\n3.  `DataExplorer`\n\n:::\n\n## `dplyr` Package\n\n:::{style=\"text-align:justify\"}\n\nThe `dplyr` is a powerful R-package to manipulate, clean and summarize unstructured data. In short, it makes data exploration and data manipulation easy and fast in R.\n\n![](images/dplyr.png){fig-align=\"center\" width=\"300\"}\n\nThere are many verbs in `dplyr` that are useful, some of them are given here...\n\n![Important functions of the dplyr package to remember](images/dplyr_fns.JPG){fig-align=\"center\" width=\"300\"}\n\n![Syntax structure of the dplyr verb](images/dplyr-verb.png){fig-align=\"center\" width=\"280\"}\n\n:::\n\n### Getting used to the pipe `|>` or `%>%`\n\n:::{style=\"text-align:justify\"}\n\n![The pipe operator in dplyr](images/dplyr-pipe.png){fig-align=\"center\" width=\"280\"}\n\n*Note*\n\n*The pipe `|>` means THEN...*\n\n*The pipe is an operator in R that allows you to chain together functions in `dplyr`.*\n\nLet's find the bottom 50 rows of tb without and with the pipe.\n\n*Tips* The native pipe \\|\\> is preferred.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#without the pipe\ntail(df, n = 50)\n\n#with the pipe\ndf |> tail(n = 50)\n```\n:::\n\n\n\n\nNow let's see what the code looks like if we need 2 functions. Find the unique age in the bottom 50 rows of df\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#without the pipe\nunique(tail(df, n = 50)$age)\n\n# with the pipe\ndf |> \n  tail(50) |>\n  distinct(age)\n```\n:::\n\n\n\n\n*Note*\n\n*The shortcut for the pipe is `Ctrl+Shift+M`*\n\nYou will notice that we used different functions to complete our task. The code without the pipe uses functions from base R while the code with the pipe uses a mixture (`tail()` from base R and `distinct()` from `dplyr`). Not all functions work with the pipe, but we will usually opt for those that do when we have a choice.\n\n:::\n\n### `distinct()` and `count()`\n\n:::{style=\"text-align:justify\"}\n\nThe `distinct()` function will return the distinct values of a column, while `count()` provides both the distinct values of a column and then number of times each value shows up. The following example investigates the different race (`race`) in the `df` dataset:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf |> \n  distinct(race) \n\ndf |> \n  count(race)\n```\n:::\n\n\n\n\nNotice that there is a new column produced by the count function called `n`.\n\n:::\n\n### `arrange()`\n\n:::{style=\"text-align:justify\"}\n\nThe `arrange()` function does what it sounds like. It takes a data frame or tbl and arranges (or sorts) by column(s) of interest. The first argument is the data, and subsequent arguments are columns to sort on. Use the `desc()` function to arrange by descending.\n\nThe following code would get the number of times each race is in the dataset:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf |> \n  count(race) |> \n  arrange(n)\n\n# Since the default is ascending order, \n# we are not getting the results that are probably useful, \n# so let's use the desc() function\ndf |> \n  count(race) |> \n  arrange(desc(n))\n\n# shortcut for desc() is -\ndf |> \n  count(race) |> \n  arrange(-n)\n```\n:::\n\n\n\n\n:::\n\n\n### `filter()`\n\n:::{style=\"text-align:justify\"}\n\nIf you want to return **rows** of the data where some criteria are met, use the `filter()` function. This is how we subset in the tidyverse. (Base R function is `subset()`)\n\n![](images/dplyr_filter.png){fig-align=\"center\" width=\"300\"}\n\nHere are the logical criteria in R:\n\n-   `==`: *Equal to*\n-   `!=`: *Not equal to*\n-   `>`: *Greater than*\n-   `>=`: *Greater than or equal to*\n-   `<`: *Less than*\n-   `<=`: *Less than or equal to*\n\nIf you want to satisfy *all* of multiple conditions, you can use the \"and\" operator, `&`.\n\nThe \"or\" operator `|` (the vertical pipe character, shift-backslash) will return a subset that meet *any* of the conditions.\n\nLet's see all the data for age 60 or above\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf |> \n  filter(age >= 60)\n```\n:::\n\n\n\n\nLet's just see data for white\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf |> \n  filter(race == \"White\")\n```\n:::\n\n\n\n\nBoth White and age 60 or more \n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf_60_plus_white <- df |> \n  filter(age >= 60 & race == \"White\")\n```\n:::\n\n\n\n\n::: \n\n### `%in%`\n\n:::{style=\"text-align:justify\"}\n\nTo `filter()` a categorical variable for only certain levels, we can use the `%in%` operator.\n\nLets check which are the race groups that are in the dataset.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf |> \n  select(race) |> \n  unique()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 5 Ã— 1\n  race    \n  <chr>   \n1 White   \n2 Mexican \n3 Hispanic\n4 Other   \n5 Black   \n```\n\n\n:::\n:::\n\n\n\n\nNow we'll create a vector of races we are interested in \n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nothers <- c(\"Mexican\", \n              \"Hispanic\", \n              \"Other\")\n```\n:::\n\n\n\n\n\n\nAnd use that vector to `filter()` `df` for races `%in%` `minority`\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf |> \n  filter(race %in% others)\n```\n:::\n\n\n\n\nYou can also save the results of a pipeline. Notice that the rows belonging to minority races are returned in the console. If we wanted to do something with those rows, it might be helpful to save them as their own dataset. To create a new object, we use the `<-` operator.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nothers_df <- df |> \n  filter(race %in% others)\n```\n:::\n\n\n\n\n:::\n\n### `drop_na()`\n\n:::{style=\"text-align:justify\"}\n\nThe `drop_na()` function is extremely useful for when we need to subset a variable to remove missing values.\n\nReturn the NHANES dataset without rows that were missing on the education variable\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf |> \n  drop_na(education)\n```\n:::\n\n\n\n\nReturn the dataset without any rows that had an NA in any column. \\*Use with caution because this will remove a lot of data\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf |> \n  drop_na()\n```\n:::\n\n\n\n\n:::\n\n### `select()`\n\n:::{style=\"text-align:justify\"}\n\nWhereas the `filter()` function allows you to return only certain *rows* matching a condition, the `select()` function returns only certain *columns*. The first argument is the data, and subsequent arguments are the columns you want.\n\nSee just the country, year, incidence_100k columns\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# list the column names you want to see separated by a comma\n\ndf |>\n  select(id, age, education)\n```\n:::\n\n\n\n\nUse the - sign to drop these same columns\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf |>\n  select(-age_months, -poverty, -home_rooms)\n```\n:::\n\n\n\n\n:::\n\n### `select()` helper functions\n\n:::{style=\"text-align:justify\"}\n\nThe `starts_with()`, `ends_with()` and `contains()` functions provide very useful tools for dropping/keeping several variables at once without having to list each and every column you want to keep. The function will return columns that either start with a specific string of text, ends with a certain string of text, or contain a certain string of text.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# these functions are all case sensitive\ndf |>\n  select(starts_with(\"home\"))\n\ndf |>\n  select(ends_with(\"t\"))\n\ndf |>\n  select(contains(\"_\"))\n\n# columns that do not contain -\ndf |>\n  select(-contains(\"_\"))\n```\n:::\n\n\n\n\n:::\n\n### `summarize()`\n\n:::{style=\"text-align:justify\"}\n\nThe `summarize()` function summarizes multiple values to a single value. On its own the `summarize()` function doesn't seem to be all that useful. The dplyr package provides a few convenience functions called `n()` and `n_distinct()` that tell you the number of observations or the number of distinct values of a particular variable.\n\n*Note* *`summarize()` is the same as `summarise()`*\n\nNotice that summarize takes a data frame and returns a data frame. In this case it's a 1x1 data frame with a single row and a single column.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf |>\n  summarize(mean(age))\n\n# watch out for nas. Use na.rm = TRUE to run the calculation after excluding nas.\n\ndf |>\n  summarize(mean(weight, na.rm = TRUE))\n```\n:::\n\n\n\n\nThe name of the column is the expression used to summarize the data. This usually isn't pretty, and if we wanted to work with this resulting data frame later on, we'd want to name that returned value something better.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf |>\n  summarize(mean_age = mean(age, na.rm = TRUE))\n```\n:::\n\n\n\n\n:::\n\n### `group_by()`\n\n:::{style=\"text-align:justify\"}\n\nWe saw that `summarize()` isn't that useful on its own. Neither is `group_by()`. All this does is takes an existing data frame and converts it into a grouped data frame where operations are performed by group.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf |>\n  group_by(gender) \n\ndf |>\n  group_by(gender, race)\n```\n:::\n\n\n\n\n:::\n\n### `group_by()` and `summarize()` together\n\n:::{style=\"text-align:justify\"}\n\nThe real power comes in where `group_by()` and `summarize()` are used together. First, write the `group_by()` statement. Then pipe the result to a call to `summarize()`.\n\nLet's summarize the mean incidence of tb for each year\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf |>\n  group_by(race) |>\n  summarize(mean_height = mean(height, na.rm = TRUE))\n\n#sort the output by descending mean_inc\ndf |>\n  group_by(race) |>\n  summarize(mean_height = mean(height, na.rm = TRUE))|>\n  arrange(desc(mean_height))\n```\n:::\n\n\n\n\n:::\n\n### `mutate()`\n\n:::{style=\"text-align:justify\"}\n\nMutate creates a new variable or modifies an existing one.\n\n![](images/dplyr_mutate.png){fig-align=\"center\" width=\"300\"}\n\nLets create a column called `elderly` if the age is greater than or equal to 65.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf |>\n  mutate(elderly = if_else(\n    age >= 65,\n    \"Yes\", \n    \"No\"))\n```\n:::\n\n\n\n\nThe same thing can be done using `case_when()`.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf |>\n  mutate(elderly = case_when(\n    age >= 65 ~ \"Yes\",\n    age < 65 ~ \"No\",\n    TRUE ~ NA))\n```\n:::\n\n\n\n\nLets do it again, but this time let us make it 1 and 0, 1 if age is greater than or equal to 65, 0 if otherwise.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf |>\n  mutate(old = case_when(\n    age >= 65 ~ 1,\n    age < 65 ~ 0,\n    TRUE ~ NA))\n```\n:::\n\n\n\n\n![](images/dplyr_case_when_sm.png){fig-align=\"center\" width=\"300\"}\n\n*Note*\n\n*The `if_else()` function may result in slightly shorter code if you only need to code for 2 options. For more options, nested `if_else()` statements become hard to read and could result in mismatched parentheses so `case_when()` will be a more elegant solution.*\n\nAs a second example of `case_when()`, let's say we wanted to create a new income variable that is low, medium, or high.\n\nSee the `income_hh` broken into 3 equally sized portions\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nquantile(df$income_hh, prob = c(.33, .66), na.rm = T)\n```\n:::\n\n\n\n\n*Note*\n\n*See the help file for `quanile` function or type `?quantile` in the console.*\n\nWe'll say:\n\n-   low = 30000 or less\n-   medium = between 30000 and 70000\n-   high = above 70000\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf |>\n  mutate(income_cat = case_when(\n    income_hh <= 30000 ~ \"low\",\n    income_hh > 30000 & income_hh <= 70000 ~ \"medium\",\n    income_hh > 70000 ~ \"high\",\n    TRUE ~ NA)) \n```\n:::\n\n\n\n\n:::\n\n### `join()`\n\n:::{style=\"text-align:justify\"}\n\nTypically in a data science or data analysis project one would have to work with many sources of data. The researcher must be able to combine multiple datasets to answer the questions he or she is interested in. Collectively, these multiple tables of data are called **relational data** because more than the individual datasets, its the relations that are more important.\n\nAs with the other `dplyr` verbs, there are different families of verbs that are designed to work with relational data and one of the most commonly used family of verbs are the mutating joins.\n\n![Different type of joins, represented by a series of Venn Diagram](images/dplyr_joins.jpg){fig-align=\"center\" width=\"300\"}\n\nThese include:\n\n-   `left_join(x, y)` which combines all columns in data frame `x` with those in data frame `y` but only retains rows from `x`.\n\n-   `right_join(x, y)` also keeps all columns but operates in the opposite direction, returning only rows from `y`.\n\n-   `full_join(x, y)` combines all columns of `x` with all columns of `y` and retains all rows from both data frames.\n\n-   `inner_join(x, y)` combines all columns present in either `x` or `y` but only retains rows that are present in both data frames.\n\n-   `anti_join(x, y)` returns the columns from `x` only and retains rows of `x` that are not present in `y`.\n\n-   `anti_join(y, x)` returns the columns from `y` only and retains rows of `y` that are not present in `x`.\n\n![Visual representation of the join() family of verbs](images/dplyr_joins1.png){fig-align=\"center\" width=\"500\"}\n\nApart from specifying the data frames to be joined, we also need to specify the key column(s) that is to be used for joining the data. Key columns are specified with the `by` argument, e.g. `inner_join(x, y, by = \"subject_id\")` adds columns of `y` to `x` for all rows where the values of the \"`subject_id`\" column (present in each data frame) match. If the name of the key column is different in both the dataframes, e.g. \"`subject_id`\" in `x` and \"`subj_id`\" in `y`, then you have to specify both names using `by = c(\"subject_id\" = \"subj_id\")`.\n\n**Example**\n\nLets try to join the basic information dataset (`nhanes_basic_info.csv`) with clinical dataset (`nhanes_clinical_info.rds`).\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbasic <- read_csv(\n  here(\"data\", \n       \"nhanes_basic_info.csv\"))\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nRows: 5679 Columns: 14\nâ”€â”€ Column specification â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nDelimiter: \",\"\nchr (7): gender, race, education, marital_status, home_own, work, bmi_who\ndbl (7): unique_id, age, income_hh, poverty, home_rooms, height, weight\n\nâ„¹ Use `spec()` to retrieve the full column specification for this data.\nâ„¹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n\n\n:::\n\n```{.r .cell-code}\nclinical <- read_rds(\n  here(\"data\", \n       \"nhanes_clinical_info.rds\"))\n\ndf <- basic |> \n  left_join(clinical)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nJoining with `by = join_by(unique_id)`\n```\n\n\n:::\n:::\n\n\n\n\nTry to join behaviour dataset (`nhanes_behaviour_info.rds`).\n\n:::\n\n### `pivot()`\n\n:::{style=\"text-align:justify\"}\n\nMost often, when working with our data we may have to reshape our data from long format to wide format and back. We can use the `pivot` family of functions to achieve this task. What we mean by \"the shape of our data\" is how the values are distributed across rows or columns. Here's a visual representation of the same data in two different shapes:\n\n![Long and Wide format of our data](images/long_wide.png){fig-align=\"center\" width=\"394\"}\n\n-   \"Long\" format is where we have a column for each of the types of things we measured or recorded in our data. In other words, each variable has its own column.\n\n-   \"Wide\" format occurs when we have data relating to the same measured thing in different columns. In this case, we have values related to our \"metric\" spread across multiple columns (a column each for a year).\n\nLet us now use the `pivot` functions to reshape the data in practice. The two `pivot` functions are:\n\n-   `pivot_wider()`: from long to wide format.\n-   `pivot_longer()`: from wide to long format.\n\n![](images/tidyr_pivot.png){fig-align=\"center\" width=\"394\"}\n\nLets try `pivot_longer`. Suppose we need a long data format for the `bp_sys` and `bp_sys_post` variables:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf_long <- df |> \n  pivot_longer(\n    cols = c(bp_sys, bp_sys_post),\n    names_to = \"bp_sys_cat\",\n    values_to = \"bp_value\")\n```\n:::\n\n\n\n\nLets try `pivot_wider`. Suppose we need a wide data format for `height` variable based on `race` variable.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf_wider <- df |> \n  pivot_wider(names_from = \"race\",\n              values_from = \"height\",\n              names_prefix = \"height_\")\n```\n:::\n\n\n\n\n\n:::{style=\"text-align:justify\"}\n\n#### Resources for learning more dplyr {.unnumbered}\n\n:::{style=\"text-align:justify\"}\n\n-   Check out the [Data Wrangling cheatsheet](https://rstudio.com/wp-content/uploads/2015/02/data-wrangling-cheatsheet.pdf) that covers dplyr and tidyr functions.(https://rstudio.com/wp-content/uploads/2015/02/data-wrangling-cheatsheet.pdf)\n\n-   Review the [Tibbles](https://r4ds.had.co.nz/tibbles.html) chapter of the excellent, free [***R for Data Science*** **book**](http://r4ds.had.co.nz).(https://r4ds.had.co.nz/tibbles.html)\n\n-   Check out the [Transformations](https://r4ds.had.co.nz/transform.html) chapter to learn more about the dplyr package. Note that this chapter also uses the graphing package ggplot2 which we have covered yesterday.(https://r4ds.had.co.nz/transform.html)\n\n-   Check out the [Relational Data](https://r4ds.had.co.nz/relational-data.html) chapter to learn more about the joins.(https://r4ds.had.co.nz/relational-data.html)\n\n:::\n\n\n\n\n## `skimr` Package\n\n`skimr` is designed to provide summary statistics about variables in data frames, tibbles, data tables and vectors. The core function of `skimr` is the `skim()` function, which is designed to work with (grouped) data frames, and will try coerce other objects to data frames if possible.\n\n![](images/skimr.png){fig-align=\"center\" width=\"100\"}\n\nGive `skim()` a try.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf |> \n  skimr::skim()\n```\n:::\n\n\n\n\nCheck out the names of the output of `skimr`\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf |> \n  skimr::skim() |> \n  names()\n```\n:::\n\n\n\n\nAlso works with `dplyr` verbs\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf |> \n  group_by(race) |> \n  skimr::skim()\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ndf |> \n  skimr::skim() |>\n  dplyr::select(skim_type, skim_variable, n_missing)\n```\n:::\n\n\n\n\n## `DataExplorer` Package\n\nThe `DataExplorer` package aims to automate most of data handling and visualization, so that users could focus on studying the data and extracting insights.[^exploring_data-1]\n\n[^exploring_data-1]: [DataExplorer Package](https://boxuancui.github.io/DataExplorer/)\n\n![](images/dataexplorer.png){fig-align=\"center\" width=\"100\"}\n\nThe single most important function from the `DataExplorer` package is `create_report()`\n\nTry it for yourself.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npacman::p_load(DataExplorer)\n\ncreate_report(df)\n```\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}